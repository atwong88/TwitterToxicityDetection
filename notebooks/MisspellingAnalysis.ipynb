{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misspelling Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed immediately that our Twitter sampled dataset had a much higher count of the vocabulary size between the Wikipedia social network versus our Twitter dataset. This additional vocabulary size seemed to be coming from the trend on Twitter of either intentionally misspelling words for ironic / humourous purposes, or as a way to express the timing of how long vowels would get drawn out, such as \"aaaaahhhhh\", or \"uhh ohhhhh\", and the hundreds other possible variations on those sounds. \n",
    "\n",
    "Contrast this to Wikipedia's social network, where at the time of the data collection, their discourse seemed to comprise of a much more formal way of communicating, similar to the habits of email correspondence.\n",
    "\n",
    "For this reason, we were hoping to find a network cluster that would have a low \"misspelling rate\" as a proxy for determining a similar formal communication style to the Wikipedia dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autocorrect import Speller\n",
    "spell = Speller(lang='en')\n",
    "from nltk import download, tokenize, word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mispelling(word):\n",
    "    return spell(word) != word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_mispellings(words):\n",
    "    if len(words)==0:\n",
    "        return 0\n",
    "    \n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if is_mispelling(word):\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_word(doc):\n",
    "    doc = doc.lower()  # Lower the text.\n",
    "    doc = word_tokenize(doc)  # Split into words.\n",
    "    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.\n",
    "    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    while (doc.count('n')): \n",
    "        doc.remove('n') \n",
    "    while (doc.count('br')): \n",
    "        doc.remove('br') \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning: this cell takes a *long* time to run. Like a whole day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Misspelling.csv\n",
    "sample_tweets_df = pd.read_csv('sample_with_label_and_clusters.csv')\n",
    "sample_tweets_df['TweetTextNew'] = sample_tweets_df['TweetText'].apply(preprocess_word)\n",
    "sample_tweets_df['MisspelledWordsCount'] = sample_tweets_df['TweetTextNew'].apply(number_of_mispellings)\n",
    "sample_tweets_df['MisspellRate'] = sample_tweets_df['MisspelledWordsCount']/sample_tweets_df['WordsCount']\n",
    "# remove NaNs\n",
    "sample_tweets_df = sample_tweets_df[sample_tweets_df['MisspellRate'] == sample_tweets_df['MispellRate']]\n",
    "sample_tweets_df[['TweetID','MisspellRate','MisspelledWordsCount','WordsCount','K5','K8','K10','K12']].to_csv('data/Misspelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in Misspelling.csv\n",
    "sample_tweets_df = pd.read_csv('data/Misspelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K5\n",
       "0    10.031610\n",
       "1    10.520557\n",
       "2    10.492694\n",
       "3     9.826167\n",
       "4    10.352032\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tweets_df.groupby('K5')['WordsCount'].sum() / sample_tweets_df.groupby('K5')['MisspelledWordsCount'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, there really was not any noticeable difference between the different network clusters and a misspelling rate. We expect that this could be because, although there anecdotally seems to exist different communities on Twitter that are using their accounts in a more professional setting, such as the blue-check journalists, they were not well-represented in the noise of our API listener, this was probably especially the case given the vulgarity in many of our seed words.\n",
    "\n",
    "It would be interesting to combat this by collecting more data, and downweighting certain follows, in a similar fashion to the inverse document frequency weighting. \n",
    "\n",
    "For example, since there are some accounts with hundreds of millions of followers, such as Katy Perry, those accounts should have less of an influence on defining a network following cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}