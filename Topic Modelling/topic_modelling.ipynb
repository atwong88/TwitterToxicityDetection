{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize, download\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim import models\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adrienawong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adrienawong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_stopwords():\n",
    "    return set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_corpus(docs, additional_stopwords=set(), no_below=1, no_above=0.5):\n",
    "    print('Building dictionary...')\n",
    "    dictionary = Dictionary(docs)\n",
    "    stopwords = nltk_stopwords().union(additional_stopwords)\n",
    "    stopword_ids = map(dictionary.token2id.get, stopwords)\n",
    "    dictionary.filter_tokens(stopword_ids)\n",
    "    dictionary.compactify()\n",
    "    dictionary.filter_extremes(no_below=no_below, no_above=no_above, keep_n=None)\n",
    "    dictionary.compactify()\n",
    "\n",
    "    print('Building corpus...')\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "    return dictionary, corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_wiki(comment):\n",
    "    comment = word_tokenize(comment)  # Split into words.\n",
    "    for c in comment:\n",
    "        if '\\n' in c:\n",
    "            c = c.replace('\\n', '')\n",
    "    comment = [w for w in comment if not w in stop_words]  # Remove stopwords.\n",
    "    comment = [w for w in comment if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [explanation, edits, made, username, hardcore,...\n",
       "1         [matches, background, colour, seemingly, stuck...\n",
       "2         [hey, man, really, trying, edit, war, guy, con...\n",
       "3         [ca, make, real, suggestions, improvement, won...\n",
       "4                       [sir, hero, chance, remember, page]\n",
       "                                ...                        \n",
       "159566    [second, time, asking, view, completely, contr...\n",
       "159567          [ashamed, horrible, thing, put, talk, page]\n",
       "159568    [spitzer, umm, theres, actual, article, prosti...\n",
       "159569    [looks, like, actually, put, speedy, first, ve...\n",
       "159570    [really, think, understand, came, idea, bad, r...\n",
       "Name: text_tokens, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment_text'] = df['comment_text'].fillna('fillna').str.lower()\n",
    "df['text_tokens'] = df['comment_text'].apply(preprocess_wiki)\n",
    "df['text_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dictionary...\n",
      "Building corpus...\n"
     ]
    }
   ],
   "source": [
    "dictionary_wiki, corpus_wiki = prep_corpus(df['text_tokens'])\n",
    "lda_wiki = models.ldamodel.LdaModel(corpus=corpus_wiki, id2word=dictionary_wiki, num_topics=5, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('lda_wiki.pkl', 'wb')\n",
    "pickle.dump(lda_wiki, file)\n",
    "file.close()\n",
    "\n",
    "file = open('dictionary_wiki.pkl', 'wb')\n",
    "pickle.dump(dictionary_wiki, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading dictionary and model files:\n",
    "\n",
    "# with open('lda_wiki.pkl', 'rb') as f:\n",
    "#     lda_wiki = pickle.load(f)\n",
    "# with open('dictionary_wiki.pkl', 'rb') as f:\n",
    "#     dictionary_wiki = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = [dictionary_wiki.doc2bow(text) for text in df['text_tokens']]\n",
    "topics = pd.DataFrame(dict(lda_wiki[x]) for x in mm)\n",
    "df['topics'] = topics.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to CSV\n"
     ]
    }
   ],
   "source": [
    "#Write to CSV\n",
    "print('Writing to CSV')\n",
    "df.to_csv(\"topic_modelling_wiki.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('http', 0.0063881697),\n",
       "   ('also', 0.0063691023),\n",
       "   ('one', 0.006343619),\n",
       "   ('article', 0.0055740587),\n",
       "   ('name', 0.004725555),\n",
       "   ('new', 0.004707772),\n",
       "   ('first', 0.004024193),\n",
       "   ('list', 0.003901345),\n",
       "   ('would', 0.003892216),\n",
       "   ('used', 0.003563209)]),\n",
       " (1,\n",
       "  [('article', 0.014565899),\n",
       "   ('would', 0.009152092),\n",
       "   ('one', 0.007617213),\n",
       "   ('page', 0.0074247657),\n",
       "   ('like', 0.0072036837),\n",
       "   ('think', 0.0069368244),\n",
       "   ('wikipedia', 0.0063149254),\n",
       "   ('know', 0.006283714),\n",
       "   ('talk', 0.0057841027),\n",
       "   ('see', 0.005445318)]),\n",
       " (2,\n",
       "  [('fuck', 0.030818222),\n",
       "   ('lol', 0.026561284),\n",
       "   ('fat', 0.014609777),\n",
       "   ('go', 0.014600924),\n",
       "   ('hate', 0.013998529),\n",
       "   ('faggot', 0.013663317),\n",
       "   ('hey', 0.013011995),\n",
       "   ('fucking', 0.012422295),\n",
       "   ('u', 0.01149223),\n",
       "   ('dont', 0.011053541)]),\n",
       " (3,\n",
       "  [('people', 0.008179867),\n",
       "   ('aids', 0.007787954),\n",
       "   ('jew', 0.0059157857),\n",
       "   ('freedom', 0.004266559),\n",
       "   ('us', 0.0041607697),\n",
       "   ('war', 0.0040959264),\n",
       "   ('state', 0.0040032244),\n",
       "   ('world', 0.0035810915),\n",
       "   ('states', 0.003518743),\n",
       "   ('country', 0.003242047)]),\n",
       " (4,\n",
       "  [('wikipedia', 0.040265225),\n",
       "   ('page', 0.03452396),\n",
       "   ('please', 0.029657904),\n",
       "   ('talk', 0.02570531),\n",
       "   ('article', 0.019760534),\n",
       "   ('deletion', 0.013933417),\n",
       "   ('image', 0.012999501),\n",
       "   ('use', 0.012032199),\n",
       "   ('pages', 0.011057113),\n",
       "   ('thank', 0.010512544)])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_wiki.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the Twitter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>UserName</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>TweetDateTime</th>\n",
       "      <th>Followers</th>\n",
       "      <th>UserID</th>\n",
       "      <th>WasDeleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1244721273793646594</td>\n",
       "      <td>ShannePanne</td>\n",
       "      <td>b'Rhoa'</td>\n",
       "      <td>2020-03-30 20:20:52</td>\n",
       "      <td>287</td>\n",
       "      <td>990004076829200385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1244721275232301058</td>\n",
       "      <td>25_ShadesOfK</td>\n",
       "      <td>b'@HisTemp_TAYtion Lol I learned from that shi...</td>\n",
       "      <td>2020-03-30 20:20:52</td>\n",
       "      <td>1189</td>\n",
       "      <td>624244930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1244721275936878593</td>\n",
       "      <td>PlagueJesterSky</td>\n",
       "      <td>b'Trying to set up the stream and I keep getti...</td>\n",
       "      <td>2020-03-30 20:20:52</td>\n",
       "      <td>415</td>\n",
       "      <td>755613447702847488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1244721278650650624</td>\n",
       "      <td>spitbull1963</td>\n",
       "      <td>b'@EricksonReal @Ilhan And you can test as muc...</td>\n",
       "      <td>2020-03-30 20:20:53</td>\n",
       "      <td>16</td>\n",
       "      <td>47425986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1244721278931664896</td>\n",
       "      <td>kamanfrancis</td>\n",
       "      <td>b'Me taking notes for the future when I\\xe2\\x8...</td>\n",
       "      <td>2020-03-30 20:20:53</td>\n",
       "      <td>1928</td>\n",
       "      <td>269295980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              TweetID         UserName  \\\n",
       "0           0  1244721273793646594      ShannePanne   \n",
       "1           1  1244721275232301058     25_ShadesOfK   \n",
       "2           2  1244721275936878593  PlagueJesterSky   \n",
       "3           3  1244721278650650624     spitbull1963   \n",
       "4           4  1244721278931664896     kamanfrancis   \n",
       "\n",
       "                                           TweetText        TweetDateTime  \\\n",
       "0                                            b'Rhoa'  2020-03-30 20:20:52   \n",
       "1  b'@HisTemp_TAYtion Lol I learned from that shi...  2020-03-30 20:20:52   \n",
       "2  b'Trying to set up the stream and I keep getti...  2020-03-30 20:20:52   \n",
       "3  b'@EricksonReal @Ilhan And you can test as muc...  2020-03-30 20:20:53   \n",
       "4  b'Me taking notes for the future when I\\xe2\\x8...  2020-03-30 20:20:53   \n",
       "\n",
       "   Followers              UserID  WasDeleted  \n",
       "0        287  990004076829200385           0  \n",
       "1       1189           624244930           0  \n",
       "2        415  755613447702847488           0  \n",
       "3         16            47425986           0  \n",
       "4       1928           269295980           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = pd.read_csv('../data/sample_with_label.csv')\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twitter(comment):\n",
    "    comment = word_tokenize(comment)  # Split into words.\n",
    "    for c in comment:\n",
    "        if '\\'b' in c:\n",
    "            c = c.replace('\\'b', '')\n",
    "        if '\\\\x' in c:\n",
    "            c = c.replace('\\\\x', ' \\\\x')\n",
    "    comment = [w for w in comment if not w in stop_words]  # Remove stopwords.\n",
    "    comment = [w for w in comment if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                       []\n",
       "1        [b, lol, learned, shit, putting, eggs, one, ba...\n",
       "2        [set, stream, keep, getting, error, code, come...\n",
       "3        [b, ericksonreal, ilhan, test, much, like, fuc...\n",
       "4        [taking, notes, future, rush, got, ta, daughte...\n",
       "                               ...                        \n",
       "29444    [b, mertipekcix, bu, realde, sadece, fuck, ne,...\n",
       "29445    [girls, onlyfans, making, bread, rn, world, come]\n",
       "29446    [b, forlornjunkheap, brujahistorica, serena, s...\n",
       "29447     [b, whos, favorite, animal, crossing, character]\n",
       "29448    [b, torqueaboutit, nothing, go, absolutely, no...\n",
       "Name: text_tokens, Length: 29449, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df['TweetText'] = twitter_df['TweetText'].fillna('fillna').str.lower()\n",
    "twitter_df['text_tokens'] = twitter_df['TweetText'].apply(preprocess_twitter)\n",
    "twitter_df['text_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dictionary...\n",
      "Building corpus...\n"
     ]
    }
   ],
   "source": [
    "dictionary_twitter, corpus_twitter = prep_corpus(twitter_df['text_tokens'])\n",
    "lda_twitter = models.ldamodel.LdaModel(corpus=corpus_twitter, id2word=dictionary_twitter, num_topics=5, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('lda_twitter.pkl', 'wb')\n",
    "pickle.dump(lda_twitter, file)\n",
    "file.close()\n",
    "\n",
    "file = open('dictionary_twitter.pkl', 'wb')\n",
    "pickle.dump(dictionary_twitter, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading dictionary and model files:\n",
    "\n",
    "# with open('lda_twitter.pkl', 'rb') as f:\n",
    "#     lda_twitter = pickle.load(f)\n",
    "# with open('dictionary_twitter.pkl', 'rb') as f:\n",
    "#     dictionary_twitter = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = [dictionary_twitter.doc2bow(text) for text in twitter_df['text_tokens']]\n",
    "topics = pd.DataFrame(dict(lda_twitter[x]) for x in mm)\n",
    "twitter_df['topics'] = topics.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to CSV\n"
     ]
    }
   ],
   "source": [
    "#Write to CSV\n",
    "print('Writing to CSV')\n",
    "twitter_df.to_csv(\"topic_modelling_twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('cunt', 0.0298522),\n",
       "   ('pay', 0.008277647),\n",
       "   ('sorry', 0.006177196),\n",
       "   ('called', 0.0049548536),\n",
       "   ('kill', 0.0047159223),\n",
       "   ('parents', 0.0038456004),\n",
       "   ('birthday', 0.0028735774),\n",
       "   ('three', 0.0028130827),\n",
       "   ('wait', 0.002510068),\n",
       "   ('video', 0.002494603)]),\n",
       " (1,\n",
       "  [('fuck', 0.08043622),\n",
       "   ('like', 0.019773507),\n",
       "   ('people', 0.012822449),\n",
       "   ('shit', 0.010465467),\n",
       "   ('get', 0.010316776),\n",
       "   ('fucking', 0.009629459),\n",
       "   ('know', 0.0091151),\n",
       "   ('go', 0.008082516),\n",
       "   ('would', 0.007985728),\n",
       "   ('bitch', 0.0075952075)]),\n",
       " (2,\n",
       "  [('bread', 0.06674111),\n",
       "   ('hands', 0.020240443),\n",
       "   ('https', 0.01815345),\n",
       "   ('wash', 0.0177393),\n",
       "   ('stay', 0.011291202),\n",
       "   ('home', 0.00843354),\n",
       "   ('make', 0.008258244),\n",
       "   ('banana', 0.007285472),\n",
       "   ('amp', 0.0070819524),\n",
       "   ('get', 0.0061140424)]),\n",
       " (3,\n",
       "  [('crossing', 0.1228715),\n",
       "   ('animal', 0.11893973),\n",
       "   ('https', 0.023913952),\n",
       "   ('play', 0.014366834),\n",
       "   ('new', 0.0121812085),\n",
       "   ('switch', 0.0116302),\n",
       "   ('island', 0.0101311095),\n",
       "   ('playing', 0.00936771),\n",
       "   ('de', 0.0089924745),\n",
       "   ('que', 0.005933257)]),\n",
       " (4,\n",
       "  [('fuck', 0.032083973),\n",
       "   ('na', 0.029063586),\n",
       "   ('gon', 0.014804282),\n",
       "   ('wan', 0.013108144),\n",
       "   ('https', 0.0077867005),\n",
       "   ('want', 0.0060272417),\n",
       "   ('sugar', 0.00563886),\n",
       "   ('baby', 0.0054623103),\n",
       "   ('hair', 0.0043458436),\n",
       "   ('daddy', 0.004021526)])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_twitter.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
